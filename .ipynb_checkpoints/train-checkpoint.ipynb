{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import pytorch_ssim\n",
    "import  time \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.modules.loss import _Loss \n",
    "from net.Ushape_Trans import *\n",
    "#from dataset import prepare_data, Dataset\n",
    "from net.utils import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
    "from loss.LAB import *\n",
    "from loss.LCH import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(img):\n",
    "    output=[]\n",
    "    output.append(F.interpolate(img, scale_factor=0.125))\n",
    "    output.append(F.interpolate(img, scale_factor=0.25))\n",
    "    output.append(F.interpolate(img, scale_factor=0.5))\n",
    "    output.append(img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = 'float32'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x=[]\n",
    "path='./data/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:x.split('.')[0])\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_x.append(imgx)   \n",
    "\n",
    "X_train = []\n",
    "\n",
    "for features in training_x:\n",
    "    X_train.append(features)\n",
    "    \n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype(dtype)\n",
    "X_train= torch.from_numpy(X_train)\n",
    "X_train=X_train.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([890, 3, 256, 256])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train/255.0\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y=[]\n",
    "path='./data/reference/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:x.split('.')[0])\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_y.append(imgx)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "y_train = []\n",
    "\n",
    "for features in training_y:\n",
    "    y_train.append(features)\n",
    "    \n",
    "\n",
    "    \n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype(dtype)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "y_train=y_train.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([890, 3, 256, 256])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y_train/255.0\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "path='./test/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:x.split('.')[0])\n",
    "for item in path_list:\n",
    "    if not item=='.DS_Store':\n",
    "        impath=path+item\n",
    "#         print(impath)\n",
    "        imgx= cv2.imread(path+item)\n",
    "        imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "        imgx=cv2.resize(imgx,(256,256))\n",
    "        test_x.append(imgx)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "x_test = []\n",
    "\n",
    "for features in test_x:\n",
    "    x_test.append(features)\n",
    "    \n",
    "\n",
    "    \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.astype(dtype)\n",
    "x_test= torch.from_numpy(x_test)\n",
    "x_test=x_test.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 3, 256, 256])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y=[]\n",
    "path='./test/output_test/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    test_Y.append(imgx)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "Y_test = []\n",
    "\n",
    "for features in test_Y:\n",
    "    Y_test.append(features)\n",
    "    \n",
    "\n",
    "    \n",
    "Y_test = np.array(Y_test)\n",
    "#X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test.astype(dtype)\n",
    "Y_test= torch.from_numpy(Y_test)\n",
    "Y_test=Y_test.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 3, 256, 256])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as dataf\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = dataf.TensorDataset(X_train,y_train)\n",
    "loader = dataf.DataLoader(dataset, batch_size=1, shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lch_Loss()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_GAN=nn.MSELoss(size_average=False)\n",
    "criterion_pixelwise=nn.MSELoss(size_average=False)\n",
    "MSE = nn.MSELoss(size_average=False)\n",
    "SSIM = pytorch_ssim.SSIM()\n",
    "L_vgg = VGG19_PercepLoss()\n",
    "L_lab=lab_Loss()\n",
    "L_lch=lch_Loss()\n",
    "\n",
    "criterion_pixelwise # .cuda()\n",
    "L_vgg #.cuda()\n",
    "MSE #.cuda()\n",
    "SSIM #.cuda()\n",
    "criterion_GAN #.cuda()\n",
    "L_lab #.cuda()\n",
    "L_lch #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel=0.1\n",
    "lambda_lab=0.001\n",
    "lambda_lch=1\n",
    "lambda_con = 100\n",
    "lambda_ssim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1, 256 // 2 ** 5, 256// 2 ** 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator() #generator = Generator().cuda()\n",
    "discriminator = Discriminator() #discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrain model found, training will start from scratch！\n"
     ]
    }
   ],
   "source": [
    "# 如果有保存的模型，则加载模型，并在其基础上继续训练\n",
    "use_pretrain=False\n",
    "if use_pretrain:\n",
    "    # Load pretrained models\n",
    "    start_epoch=795\n",
    "    generator.load_state_dict(torch.load(\"./saved_models/G/generator_%d.pth\" % (start_epoch), map_location=torch.device('cpu')))\n",
    "#     discriminator.load_state_dict(torch.load(\"saved_models/D/discriminator_%d.pth\" % (start_epoch)))\n",
    "    print('successfully loading epoch {} 成功！'.format(start_epoch))\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('No pretrain model found, training will start from scratch！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    generator.eval()\n",
    "    i=random.randrange(1,90)\n",
    "    real_A = Variable(x_test[i,:,:,:]) #.cuda()\n",
    "    real_B = Variable(Y_test[i,:,:,:]) #.cuda()\n",
    "    real_A=real_A.unsqueeze(0)\n",
    "    real_B=real_B.unsqueeze(0)\n",
    "    fake_B = generator(real_A)\n",
    "    #print(fake_B.shape)\n",
    "    imgx=fake_B[3].data\n",
    "    imgy=real_B.data\n",
    "    x=imgx[:,:,:,:]\n",
    "    y=imgy[:,:,:,:]\n",
    "    img_sample = torch.cat((x,y), -2)\n",
    "    save_image(img_sample, \"images/%s/%s.png\" % ('results', batches_done), nrow=5, normalize=True)#要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "LR=0.0005\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR,  betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR,  betas=(0.5, 0.999))\n",
    "scheduler_G=lr_scheduler.StepLR(optimizer_G,step_size=40,gamma=0.8)\n",
    "scheduler_D=lr_scheduler.StepLR(optimizer_D,step_size=40,gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 71\u001b[0m\n\u001b[1;32m     66\u001b[0m ssim_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m loss_ssim\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     67\u001b[0m loss_con \u001b[38;5;241m=\u001b[39m (L_vgg(fake_B[\u001b[38;5;241m0\u001b[39m], real_B1[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     68\u001b[0m             L_vgg(fake_B[\u001b[38;5;241m1\u001b[39m], real_B1[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     69\u001b[0m             L_vgg(fake_B[\u001b[38;5;241m2\u001b[39m], real_B1[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     70\u001b[0m             L_vgg(fake_B[\u001b[38;5;241m3\u001b[39m], real_B1[\u001b[38;5;241m3\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4.0\u001b[39m\n\u001b[0;32m---> 71\u001b[0m loss_lab \u001b[38;5;241m=\u001b[39m (\u001b[43mL_lab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_B\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_B1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     72\u001b[0m             L_lab(fake_B[\u001b[38;5;241m1\u001b[39m], real_B1[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     73\u001b[0m             L_lab(fake_B[\u001b[38;5;241m2\u001b[39m], real_B1[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     74\u001b[0m             L_lab(fake_B[\u001b[38;5;241m3\u001b[39m], real_B1[\u001b[38;5;241m3\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4.0\u001b[39m\n\u001b[1;32m     75\u001b[0m loss_lch \u001b[38;5;241m=\u001b[39m (L_lch(fake_B[\u001b[38;5;241m0\u001b[39m], real_B1[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     76\u001b[0m             L_lch(fake_B[\u001b[38;5;241m1\u001b[39m], real_B1[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     77\u001b[0m             L_lch(fake_B[\u001b[38;5;241m2\u001b[39m], real_B1[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     78\u001b[0m             L_lch(fake_B[\u001b[38;5;241m3\u001b[39m], real_B1[\u001b[38;5;241m3\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4.0\u001b[39m     \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Total loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/buddy/buddy-underwater-filter/U-shape_Transformer_for_Underwater_Image_Enhancement/u-shape-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/buddy/buddy-underwater-filter/U-shape_Transformer_for_Underwater_Image_Enhancement/loss/LAB.py:38\u001b[0m, in \u001b[0;36mlab_Loss.forward\u001b[0;34m(self, img, gt)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,img,gt):\n\u001b[0;32m---> 38\u001b[0m \t    tab\u001b[38;5;241m=\u001b[39m\u001b[43mquantAB\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \t    lab_img\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mclamp(rgb2lab(img),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmin,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmax)\n\u001b[1;32m     40\u001b[0m \t    lab_gt\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mclamp(rgb2lab(gt),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmin,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmax)\n",
      "File \u001b[0;32m~/Documents/buddy/buddy-underwater-filter/U-shape_Transformer_for_Underwater_Image_Enhancement/u-shape-venv/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "import time as time\n",
    "import datetime\n",
    "import sys\n",
    "from torchvision.utils import save_image\n",
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "f1 = open('psnr.csv','w',encoding='utf-8')#要改\n",
    "csv_writer1 = csv.writer(f1)\n",
    "f2 = open('SSIM.csv','w',encoding='utf-8')#要改\n",
    "csv_writer2 = csv.writer(f2)\n",
    "\n",
    "checkpoint_interval=5\n",
    "epochs=start_epoch\n",
    "n_epochs=500\n",
    "sample_interval=1000\n",
    "\n",
    "# ingnored when opt.mode=='S'\n",
    "psnr_list = [] \n",
    "prev_time = time.time()\n",
    "\n",
    "for epoch in range(epochs,n_epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "\n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[0]) # .cuda() \n",
    "        real_B = Variable(batch[1])# .cuda()\n",
    "        #real_A1=Tensor(np.array(split(real_A)).astype(dtype))\n",
    "        #real_B1=Tensor(np.array(split(real_B)).astype(dtype))\n",
    "        real_A1=split(real_A)\n",
    "        real_B1=split(real_B)\n",
    "        #print(len(real_A1))\n",
    "        #print(len(real_B1))\n",
    "        #real_A1= torch.tensor([item.cpu().detach().numpy() for item in real_A1]).cuda() \n",
    "        #real_B1= torch.tensor([item.cpu().detach().numpy() for item in real_B1]).cuda() \n",
    "\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)#全1\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)#全0\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = generator(real_A)\n",
    "        #fake_B1 = list(map(lambda x: x.detach(), fake_B))\n",
    "        pred_fake = discriminator(fake_B, real_A1)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        # Pixel-wise loss\n",
    "        loss_pixel = (criterion_pixelwise(fake_B[0], real_B1[0])+\\\n",
    "                      criterion_pixelwise(fake_B[1], real_B1[1])+\\\n",
    "                      criterion_pixelwise(fake_B[2], real_B1[2])+\\\n",
    "                      criterion_pixelwise(fake_B[3], real_B1[3]))/4.0\n",
    "        loss_ssim=   -(SSIM(fake_B[0], real_B1[0])+\\\n",
    "                      SSIM(fake_B[1], real_B1[1])+\\\n",
    "                      SSIM(fake_B[2], real_B1[2])+\\\n",
    "                      SSIM(fake_B[3], real_B1[3]))/4.0\n",
    "        ssim_value = - loss_ssim.item()\n",
    "        loss_con = (L_vgg(fake_B[0], real_B1[0])+\\\n",
    "                    L_vgg(fake_B[1], real_B1[1])+\\\n",
    "                    L_vgg(fake_B[2], real_B1[2])+\\\n",
    "                    L_vgg(fake_B[3], real_B1[3]))/4.0\n",
    "        loss_lab = (L_lab(fake_B[0], real_B1[0])+\\\n",
    "                    L_lab(fake_B[1], real_B1[1])+\\\n",
    "                    L_lab(fake_B[2], real_B1[2])+\\\n",
    "                    L_lab(fake_B[3], real_B1[3]))/4.0\n",
    "        loss_lch = (L_lch(fake_B[0], real_B1[0])+\\\n",
    "                    L_lch(fake_B[1], real_B1[1])+\\\n",
    "                    L_lch(fake_B[2], real_B1[2])+\\\n",
    "                    L_lch(fake_B[3], real_B1[3]))/4.0     \n",
    "        \n",
    "\n",
    "        # Total loss\n",
    "        loss_G = (loss_GAN + lambda_pixel * loss_pixel+lambda_ssim*loss_ssim+\\\n",
    "        lambda_con*loss_con+lambda_lab*loss_lab+lambda_lch*loss_lch)\n",
    "\n",
    "        loss_G.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = discriminator(real_B1, real_A1)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_B[0]=fake_B[0].detach()\n",
    "        fake_B[1]=fake_B[1].detach()\n",
    "        fake_B[2]=fake_B[2].detach()\n",
    "        fake_B[3]=fake_B[3].detach()\n",
    "        pred_fake1 = discriminator(fake_B, real_A1)\n",
    "        loss_fake = criterion_GAN(pred_fake1, fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        #loss_D=loss_real\n",
    "\n",
    "        loss_D.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(loader) + i\n",
    "        batches_left = n_epochs * len(loader) - batches_done\n",
    "        out_train= torch.clamp(fake_B[3], 0., 1.) \n",
    "        psnr_train = batch_PSNR(out_train,real_B, 1.)\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d][PSNR: %f] [SSIM: %f] [D loss: %f] [G loss: %f],[lab: %f],[lch: %f], [pixel: %f],[VGG_loss: %f], [adv: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                n_epochs,\n",
    "                i,\n",
    "                len(loader),\n",
    "                psnr_train,\n",
    "                ssim_value,\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                0.001*loss_lab.item(),\n",
    "                1*loss_lch.item(),\n",
    "                0.1*loss_pixel.item(),\n",
    "                100*loss_con.item(),\n",
    "                loss_GAN.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "\n",
    "        # If at sample interval save image\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "            csv_writer1.writerow([str(psnr_train)])\n",
    "            csv_writer2.writerow([str(ssim_value)])\n",
    "            \n",
    "            \n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "        # Save model checkpoints\n",
    "        torch.save(generator.state_dict(), \"saved_models/G/generator_%d.pth\" % (epoch))\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/D/discriminator_%d.pth\" % (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
